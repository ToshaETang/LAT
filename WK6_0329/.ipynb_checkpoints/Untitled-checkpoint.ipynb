{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forty-american",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#多篇文章 一個LDA圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "promising-citation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "with open('01.txt', 'r',encoding=\"utf-8\") as fh:\n",
    "    tmp1 = fh.read()\n",
    "    itemlist1 = tmp.split(',')\n",
    "with open('02.txt', 'r',encoding=\"utf-8\") as fh:\n",
    "    tmp2 = fh.read()\n",
    "    itemlist2 = tmp.split(',')\n",
    "with open('03.txt', 'r',encoding=\"utf-8\") as fh:\n",
    "    tmp3 = fh.read()\n",
    "    itemlist3 = tmp.split(',')\n",
    "\n",
    "itemlist = itemlist1 + itemlist2 + itemlist3\n",
    "itemlist = str(itemlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "serial-pennsylvania",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['Copyright © by Lincoln Paine', ' The Sea and Civilization: A Maritime History of \\\\nthe World (New York: Knopf', ' 2013; ISBN 978-1-4000-4409-2 (hardback); Lon\\\\x02don: Atlantic Books', ' 2014; ISBN 978-1782393559 (hardback)). Available as an e\\\\x02book. To be published in Chinese', ' Korean', ' Romanian', ' and Russian translation.\\\\nIntroduction \\\\nI want to change the way you see the world. Specifically', ' I want to change the \\\\nway you see the world map by focusing your attention on the blues that shade \\\\n70 percent of the image before you', ' and letting the earth tones fade. This shift \\\\nin emphasis from land to water makes many trends and patterns of world histo\\\\x02ry stand out in ways they simply cannot otherwise. Before the development of \\\\nthe marine steam engine in the nineteenth century', ' culture', ' commerce', ' conta\\\\x02gion', ' and conflict generally moved faster by sea than by land. The opening of \\\\nsea routes sometimes resulted in immediate transformation', ' but more often it \\\\nlaid the groundwork for what was later mistaken for sudden change. The best \\\\nexample of this is the trade networks of the Indian Ocean', ' the oldest of which \\\\nwere pioneered at least four thousand years ago by navigators sailing between \\\\nMesopotamia and the mouths of the Indus River. By the start of the common \\\\nera two thousand years ago', ' the Indian subcontinent was a point of departure \\\\nand destination for merchants and mendicants from across the Arabian Sea \\\\nand the Bay of Bengal. This is all but unnoticed in the written record', ' which \\\\nboasts of no figure comparable to a Gilgamesh or Odysseus', ' and despite a\\\\ngrowing body of archaeological evidence', ' these undertakings remain largely \\\\nunrecognized. As a result', ' the later arrival in Southeast Asia of Muslim trad\\\\x02ers from the Indian subcontinent and Southwest Asia', ' of Chinese merchants \\\\nof various faiths', ' and of Portuguese Christians seem like so many historical \\\\nsurprises. Only the last were absolute newcomers to the Monsoon Seas that \\\\nstretch from the shores of East Africa to the coasts of Korea and Japan. The \\\\nothers were heirs to ancient', ' interlinked traditions of seafaring and trade that \\\\nlong ago connected the shores of East Africa with those of Northeast Asia. \\\\nThis book shows many similar examples of maritime regions that were quietly\\\\n \\\\n4 T H E S E A A N D C I V I L I Z AT I O N\\\\nexploited before events conspired to thrust them into the historical limelight. \\\\nTwo questions merit consideration before taking on a maritime history of the \\\\nworld as either writer or reader: What is maritime history? and What is world \\\\nhistory? The answers to both have as much to do with perspective as with sub\\\\x02ject matter. World history involves the synthetic investigation of complex in\\\\x02teractions between people of distinct backgrounds and orientations. It therefore \\\\ntranscends historians’ more traditional focus on politically', ' religiously', ' or cul\\\\x02turally distinct communities seen primarily in their own terms at a local', ' na\\\\x02tional', ' or regional level. As a subject of interdisciplinary and interregional in\\\\x02quiry', ' maritime history is a branch \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyfile = open(\"key.txt\", \"r\",encoding=\"utf-8\")\n",
    "key = keyfile.readline()\n",
    "openai.api_key = key\n",
    "data = [itemlist[0:3200], itemlist[3201:6400], \n",
    "        itemlist[6401:9600], itemlist[9601:12800], itemlist[12801:16000]]\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "facial-pastor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport openai\\nimport pandas as pd\\nwith open(\\'01.txt\\', \\'r\\',encoding=\"utf-8\") as fh:\\n    tmp = fh.read()\\n    itemlist = tmp.split(\\',\\')\\nitemlist = str(itemlist)\\nkeyfile = open(\"key.txt\", \"r\",encoding=\"utf-8\")\\nkey = keyfile.readline()\\nopenai.api_key = key\\ndata = [itemlist[0:3200], itemlist[3201:6400], \\n        itemlist[6401:9600], itemlist[9601:12800], itemlist[12801:16000]]\\ndata[0]\\n\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import openai\n",
    "import pandas as pd\n",
    "with open('01.txt', 'r',encoding=\"utf-8\") as fh:\n",
    "    tmp = fh.read()\n",
    "    itemlist = tmp.split(',')\n",
    "itemlist = str(itemlist)\n",
    "keyfile = open(\"key.txt\", \"r\",encoding=\"utf-8\")\n",
    "key = keyfile.readline()\n",
    "openai.api_key = key\n",
    "data = [itemlist[0:3200], itemlist[3201:6400], \n",
    "        itemlist[6401:9600], itemlist[9601:12800], itemlist[12801:16000]]\n",
    "data[0]\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "manufactured-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 50271f49660e9df674ed3048a47b59d3 in your message.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-26ca6b333c8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchatgptfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-26ca6b333c8e>\u001b[0m in \u001b[0;36mchatgptfn\u001b[1;34m(sub_list)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchatgptfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         messages=[\n",
      "\u001b[1;32mc:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    151\u001b[0m         )\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         )\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             return (\n\u001b[1;32m--> 619\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"error\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 50271f49660e9df674ed3048a47b59d3 in your message.)"
     ]
    }
   ],
   "source": [
    "def chatgptfn(sub_list):\n",
    "    result = ''\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{sub_list} :give me a summary\"}\n",
    "        ]\n",
    "    )\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content\n",
    "    return result\n",
    "\n",
    "for i in range(1,5):\n",
    "    data[i] = chatgptfn(data[i])\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "other-transparency",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tosha.e.t\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\Tosha.E.T\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<508 unique tokens: [\"'\", '(hardback)).', '(hardback);', '(new', '2013;']...>\n",
      "Dictionary<442 unique tokens: [\"'\", '(hardback)).', '(hardback);', '(new', '2013;']...>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1732820054159848165470980777\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1732820054159848165470980777_data = {\"mdsDat\": {\"x\": [-0.09314652427061454, 0.09416189373824996, -0.0010153694676354663], \"y\": [0.0, 0.0, 0.0], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [73.11817108735242, 26.86807428891512, 0.013754623732447705]}, \"tinfo\": {\"Term\": [\"'\", \"i\", \"before\", \"what\", \"indian\", \"subcontinent\", \"thousand\", \"change\", \"shores\", \"distinct\", \"e\", \"ago\", \"africa\", \"later\", \"merchants\", \"trade\", \"isbn\", \"want\", \"you\", \"\\\\nand\", \"some\", \"not\", \"east\", \"years\", \"\\\\nthe\", \"author\", \"muslim\", \"orientations.\", \"opening\", \"remain\", \"'\", \"i\", \"before\", \"what\", \"indian\", \"not\", \"some\", \"subcontinent\", \"later\", \"change\", \"shores\", \"trade\", \"ago\", \"thousand\", \"distinct\", \"africa\", \"e\", \"merchants\", \"years\", \"east\", \"you\", \"\\\\nand\", \"\\\\nthe\", \"isbn\", \"want\", \"versions\", \"nationalist\", \"nationalism.\", \"exceptionalism.\", \"periods\", \"author\", \"spanish\", \"study\", \"political\", \"such\", \"spread\", \"relationship\", \"ships,\", \"states\", \"can\", \"central\", \"transportation.\", \"discovery\", \"importance\", \"access\", \"americas\", \"been\", \"rest\", \"speaking\", \"navigable\", \"colonization,\", \"united\", \"ignored\", \"shaped\", \"sailors,\", \"ports,\", \"praised\", \"are\", \"west\", \"putting\", \"played\", \"role\", \"growth,\", \"away\", \"economy.\", \"affairs.\", \"take\", \"moving\", \"shaping\", \"offering\", \"mediterranean\", \"economic\", \"draws\", \"oceanic\", \"shipbuilding,\", \"exploration,\", \"insights\", \"allowing\", \"global\", \"approach.\", \"unique\", \"covers\", \"place\", \"arts,\", \"migration\", \"disciplines,\", \"crucial\", \"trade,\", \"topics\", \"relation\", \"expansion.\", \"political\", \"'\", \"i\", \"what\", \"study\", \"before\", \"indian\", \"such\", \"thousand\", \"distinct\", \"change\", \"e\", \"subcontinent\", \"want\", \"shores\", \"isbn\"], \"Freq\": [19.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 19.522145354277594, 3.8062286834833836, 3.0902808581358467, 2.3814011727422195, 2.3791752582439862, 1.6708208679978138, 1.670654268979254, 1.6671484536445367, 1.666877105708413, 1.6665476979281793, 1.6665933532952095, 1.6667644317082704, 1.6663052937719087, 1.6660501405697505, 1.6660348072578046, 1.666182110423129, 1.6660491068633272, 1.6658442607071045, 1.6657994667620935, 1.6657384780831173, 1.6656070250829507, 1.6655922086242163, 1.6657389949363288, 1.6653158644403798, 1.6650576101189516, 0.9549814956825243, 0.9549058628292174, 0.9548523685218102, 0.9548538329392433, 0.9548555557832822, 1.5890865485354766, 1.1152011160911572, 1.1140227048010067, 1.1135586586660113, 1.113295424855737, 1.1137942902778057, 0.6374270023586948, 0.6373633147172479, 0.6373309011263724, 0.6373225444974748, 0.6373212783415813, 0.6373032356200977, 0.6372993105368276, 0.6372919668326449, 0.6372757600372072, 0.637271645030553, 0.6372839900505154, 0.6372628452470928, 0.6372665804069787, 0.6372670235615415, 0.6372582870858758, 0.6372623387847353, 0.637251956306408, 0.637222771413061, 0.637219036253175, 0.6372171370193347, 0.637201689917433, 0.6372098566229466, 0.6371964986782693, 0.6371862428155314, 0.000158149969470832, 0.00015811731712301512, 0.00015801376947906982, 0.00015801078782547265, 0.0001580041601280746, 0.00015800226418529812, 0.00015799657635696873, 0.00015796047242102037, 0.00015796499351533347, 0.0001579378345401766, 0.00015791675230468792, 0.00015792143544539217, 0.00015791033526759834, 0.00015786462198065472, 0.0001578745878337105, 0.0001578332011854106, 0.00015784412311217416, 0.00015783509712818708, 0.0001578298630297529, 0.0001578141769390895, 0.00015780827845045164, 0.00015778658043867654, 0.0001577708295294567, 0.00015775506241559774, 0.00015776731312276874, 0.0001577469438914011, 0.0001577349038445386, 0.00015774013794297276, 0.00015771915293531875, 0.00015769915641065076, 0.000157706513316809, 0.00015851925699162528, 0.000161829459646856, 0.00015874642982737945, 0.00015828639632754174, 0.00015825905910135462, 0.00015825609365239656, 0.00015816361377696687, 0.00015815481465792738, 0.00015799375674976272, 0.00015793324862730705, 0.00015793294073916387, 0.0001579058951964808, 0.00015789113277024698, 0.00015789085729138203, 0.00015787797460328556, 0.0001578748957218537], \"Total\": [19.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 19.72397778805769, 3.9753537023110717, 3.2593326617982226, 2.545136734649121, 2.544520646240916, 1.8314934277982102, 1.8314197984687464, 1.8295841644943047, 1.8296428987850744, 1.829341725222952, 1.829412648741718, 1.8296163440852562, 1.8293507861763267, 1.8291145054829663, 1.829170696951731, 1.8293359440662795, 1.8292031227139467, 1.8292105678677923, 1.8293783871006721, 1.829330451321473, 1.829191368805876, 1.8292072676043387, 1.8293857541528513, 1.828990350152425, 1.828888387083731, 1.1150314192012931, 1.1150072387534238, 1.1149810857535072, 1.114984114559549, 1.1149922556582044, 1.836212261822759, 1.355553198821931, 1.354620453395271, 1.3544561408232243, 1.3551408820718178, 1.3563449635589375, 0.8769876901489098, 0.8770198569509925, 0.8770358554396559, 0.8770314453584839, 0.8770408980892669, 0.8770359151642267, 0.8770386225605719, 0.8770549380647794, 0.8770367457859058, 0.8770363794720676, 0.8770534901194679, 0.8770328611649841, 0.8770634729183266, 0.877066971625544, 0.8770555535446274, 0.8770658424346035, 0.8770613885524691, 0.8770679793939641, 0.8770662494385598, 0.8770850986460014, 0.8770856141187644, 0.8770972808290615, 0.877087809865101, 0.8771100398372084, 0.8761421393650878, 0.8762712250418812, 0.8763037513769438, 0.8763486986873014, 0.8763589697126128, 0.8764026023874026, 0.8764786199591417, 0.8763275937897307, 0.8763939718457961, 0.8764290958547482, 0.8764457809451159, 0.8765183313651278, 0.8765123810472155, 0.8763931974479714, 0.8765742461020851, 0.8764351569531751, 0.8765102732915391, 0.8765109325296756, 0.8765748283373207, 0.8765375181504704, 0.8765710121150989, 0.8765845532346284, 0.8766331278184577, 0.8765773373128741, 0.8766472759296874, 0.8766528847025425, 0.8766182808784819, 0.876679204195447, 0.876598701979496, 0.8766328640155527, 0.8766795951742429, 1.3544561408232243, 19.72397778805769, 3.9753537023110717, 2.545136734649121, 1.354620453395271, 3.2593326617982226, 2.544520646240916, 1.3551408820718178, 1.8291145054829663, 1.829170696951731, 1.829341725222952, 1.8292031227139467, 1.8295841644943047, 1.828888387083731, 1.829412648741718, 1.828990350152425], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.9419, -4.5768, -4.7852, -5.0458, -5.0467, -5.4001, -5.4002, -5.4023, -5.4025, -5.4027, -5.4027, -5.4026, -5.4028, -5.403, -5.403, -5.4029, -5.403, -5.4031, -5.4031, -5.4032, -5.4033, -5.4033, -5.4032, -5.4034, -5.4036, -5.9595, -5.9596, -5.9596, -5.9596, -5.9596, -4.4491, -4.8033, -4.8043, -4.8047, -4.805, -4.8045, -5.3626, -5.3627, -5.3628, -5.3628, -5.3628, -5.3628, -5.3628, -5.3628, -5.3629, -5.3629, -5.3628, -5.3629, -5.3629, -5.3629, -5.3629, -5.3629, -5.3629, -5.3629, -5.3629, -5.363, -5.363, -5.363, -5.363, -5.363, -6.087, -6.0872, -6.0878, -6.0878, -6.0879, -6.0879, -6.0879, -6.0882, -6.0881, -6.0883, -6.0884, -6.0884, -6.0885, -6.0888, -6.0887, -6.089, -6.0889, -6.0889, -6.089, -6.0891, -6.0891, -6.0893, -6.0894, -6.0895, -6.0894, -6.0895, -6.0896, -6.0895, -6.0897, -6.0898, -6.0898, -6.0846, -6.064, -6.0832, -6.0861, -6.0863, -6.0863, -6.0869, -6.0869, -6.0879, -6.0883, -6.0883, -6.0885, -6.0886, -6.0886, -6.0887, -6.0887], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3028, 0.2696, 0.2598, 0.2466, 0.2459, 0.2213, 0.2212, 0.2201, 0.2199, 0.2199, 0.2199, 0.2199, 0.2197, 0.2197, 0.2197, 0.2197, 0.2197, 0.2195, 0.2194, 0.2194, 0.2194, 0.2194, 0.2194, 0.2193, 0.2192, 0.1581, 0.1581, 0.1581, 0.1581, 0.1581, 1.1697, 1.1191, 1.1187, 1.1184, 1.1177, 1.1172, 0.9952, 0.995, 0.995, 0.995, 0.995, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9948, 0.9948, 0.9948, 0.9948, 0.9948, 0.9948, 0.9948, 0.9947, 0.9947, 0.9947, 0.9947, 0.9947, 0.2718, 0.2715, 0.2708, 0.2707, 0.2706, 0.2706, 0.2705, 0.2704, 0.2704, 0.2701, 0.27, 0.2699, 0.2699, 0.2697, 0.2696, 0.2695, 0.2695, 0.2694, 0.2693, 0.2692, 0.2692, 0.269, 0.2689, 0.2688, 0.2688, 0.2687, 0.2686, 0.2686, 0.2686, 0.2684, 0.2684, -0.1615, -2.8193, -1.2368, -0.7937, -0.1632, -1.0413, -0.7943, -0.1643, -0.4652, -0.4657, -0.4657, -0.4658, -0.4661, -0.4658, -0.4661, -0.4659]}, \"token.table\": {\"Topic\": [1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1], \"Freq\": [1.0139942467441547, 1.0933698085615764, 1.0932631324256465, 1.1402030813474158, 1.1410281042935135, 1.0932929003485088, 1.0932840301123226, 1.1408870818232988, 1.1402035575787066, 1.1408524784085003, 1.1401243874051996, 1.1408006543558096, 1.0891986953701382, 1.1410982882703178, 1.1401813130733736, 0.9204338161496087, 1.1402099722789907, 1.140197683116732, 1.0932894452818809, 1.1401786305992723, 1.1407912634439703, 1.1407473718182948, 1.1407023434814914, 1.1402006414272092, 1.0933916683297802, 1.1408851964021858, 1.0933722860874224, 1.0932961830680938, 1.1408774514077265, 1.1410849144705315, 0.8968737643361215, 1.1406675888255924, 1.1409857216093244, 1.1408039196115078, 1.1411568174034301, 1.006199774796039, 1.140171045096892, 1.1401794307281352, 0.7860026614264852, 1.140887939903685, 1.0934994817404713, 1.0931094812698405, 1.1409718909498878, 1.0933678359027235, 1.1407096416737241, 1.1411257697312036, 0.8977097275216985, 0.8968762006614645, 0.8968551640238662, 1.1401637872038592, 1.092005010580008, 1.1410403491400523, 1.1409936122952853, 0.8979143128444771, 0.8978785040075535, 0.8968672158262463, 1.140728051754725, 1.1413673136697524, 0.7383037145759556, 1.1401402230453446, 1.1401395529725242, 1.1401078024207771, 1.140728395031125, 1.1402668603366635, 0.8977771709715249, 1.1402081316219732, 1.1411991760338875, 1.1401647260285461, 1.1401624771331629, 1.1410393408958233, 1.1408046773524998, 1.1402250383207453, 1.0932470601291695, 1.0920489129101933, 0.7377062005895961, 1.1401683354485352, 0.7372755654845227, 1.140204238854867, 0.7382141599099311, 1.093144572855875, 0.7379306559412052, 1.1409291421696246, 1.0934252579621375, 1.1407728504980041, 1.0931253464506678, 1.1406680975371464, 1.140204161209006, 1.1408088861928898, 1.140165255124005, 0.896835714922104, 1.0935604458559205, 1.1401366986890438, 0.7858123977279065, 1.0932675350831826, 1.093379311813411], \"Term\": [\"'\", \"\\\\nand\", \"\\\\nthe\", \"access\", \"affairs.\", \"africa\", \"ago\", \"allowing\", \"americas\", \"approach.\", \"are\", \"arts,\", \"author\", \"away\", \"been\", \"before\", \"can\", \"central\", \"change\", \"colonization,\", \"covers\", \"crucial\", \"disciplines,\", \"discovery\", \"distinct\", \"draws\", \"e\", \"east\", \"economic\", \"economy.\", \"exceptionalism.\", \"expansion.\", \"exploration,\", \"global\", \"growth,\", \"i\", \"ignored\", \"importance\", \"indian\", \"insights\", \"isbn\", \"later\", \"mediterranean\", \"merchants\", \"migration\", \"moving\", \"muslim\", \"nationalism.\", \"nationalist\", \"navigable\", \"not\", \"oceanic\", \"offering\", \"opening\", \"orientations.\", \"periods\", \"place\", \"played\", \"political\", \"ports,\", \"praised\", \"putting\", \"relation\", \"relationship\", \"remain\", \"rest\", \"role\", \"sailors,\", \"shaped\", \"shaping\", \"shipbuilding,\", \"ships,\", \"shores\", \"some\", \"spanish\", \"speaking\", \"spread\", \"states\", \"study\", \"subcontinent\", \"such\", \"take\", \"thousand\", \"topics\", \"trade\", \"trade,\", \"transportation.\", \"unique\", \"united\", \"versions\", \"want\", \"west\", \"what\", \"years\", \"you\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1732820054159848165470980777\", ldavis_el1732820054159848165470980777_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1732820054159848165470980777\", ldavis_el1732820054159848165470980777_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1732820054159848165470980777\", ldavis_el1732820054159848165470980777_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "# 創建詞袋\n",
    "texts = [[word for word in document.lower().split()] for document in data]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.3)######<---\n",
    "print(dictionary)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "# 訓練 LDA 模型\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, \n",
    "                                            num_topics=3, random_state=100, update_every=1, \n",
    "                                            chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
    "# 輸出主題模型分析結果\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
